{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOyO7mIwkfBJ",
        "outputId": "b1dc75b8-8993-4169-959c-6d825f2d8d0f",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "76SYfGWbn3Ec",
        "outputId": "b5e08419-9fed-47f8-cd1a-855eb6f21f63",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-299cffc3-7b13-465c-94b9-4e8ad1c40832\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-299cffc3-7b13-465c-94b9-4e8ad1c40832\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving classification_data.zip to classification_data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip classification_data.zip -d /content/classification_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k1-5ePlBn90C",
        "outputId": "7d7a53a9-399d-43b2-97c7-f0ed52924b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: /content/classification_data/classification_data/val/08502.jpg  \n",
            "  inflating: /content/classification_data/classification_data/val/08503.jpg  \n",
            "  inflating: /content/classification_data/classification_data/val/08999.jpg  \n",
            "  inflating: /content/classification_data/classification_data/val/09000.jpg  \n",
            "  inflating: /content/classification_data/classification_data/val/labels.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%rm -rf deep-learning/\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVozcsItpmid",
        "outputId": "71db1262-7d13-4840-9127-776ff57dd3ae",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[0m\u001b[01;34mclassification_data\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVfnNzhMb83O",
        "outputId": "71c2191b-a483-4377-e764-35014ddccc36",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (134/134), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 134 (delta 41), reused 123 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (134/134), 14.64 MiB | 17.83 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo\n",
        "!git clone https://github.com/laurenesco/deep-learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd deep-learning/hw2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EaTLHGaqApU",
        "outputId": "a0b8faf0-ddc9-49b4-9416-769ae69c995b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning/hw2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ../../classification_data/classification_data/ ."
      ],
      "metadata": {
        "id": "nd5TRMpyq-AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m homework.train --model_name mlp_deep_residual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X12F2UTTioLo",
        "outputId": "eabd30c0-4391-444a-eb23-001930041daa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-25 02:02:35.352498: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740448955.371793   13058 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740448955.378091   13058 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-25 02:02:35.397531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Model size: 6.19 MB\n",
            "Epoch  1 / 50: train_acc=0.7026 val_acc=0.7200\n",
            "Epoch 10 / 50: train_acc=0.9160 val_acc=0.7890\n",
            "Epoch 20 / 50: train_acc=0.9550 val_acc=0.7852\n",
            "Epoch 30 / 50: train_acc=0.9693 val_acc=0.8015\n",
            "Epoch 40 / 50: train_acc=0.9691 val_acc=0.7984\n",
            "Epoch 50 / 50: train_acc=0.9841 val_acc=0.7721\n",
            "Model saved to logs/mlp_deep_residual_0225_020240/mlp_deep_residual.th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"laurenesco@users.noreply.github.com\"\n",
        "!git config --global user.name \"lauren escobedo\"\n",
        "!git remote set-url origin https://laurenesco:<PAT_HERE>@github.com/laurenesco/deep-learning.git\n",
        "!git status"
      ],
      "metadata": {
        "id": "Q02yI4hQsayF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"trained residual deep mlp\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3TNx0Viz_as",
        "outputId": "2b8f61e0-47ce-4254-9981-42e9629e5f7c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 2cf15b7] trained residual deep mlp\n",
            " 3 files changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 hw2/homework/mlp_deep_residual.th\n",
            " create mode 100644 hw2/logs/mlp_deep_residual_0225_020240/events.out.tfevents.1740448960.e60370d6be62.13058.0\n",
            " create mode 100644 hw2/logs/mlp_deep_residual_0225_020240/mlp_deep_residual.th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBHzZ90IsRgd",
        "outputId": "aa3db4c8-8709-4c23-fcc2-f4ccd460c767",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 12, done.\n",
            "Counting objects:   8% (1/12)\rCounting objects:  16% (2/12)\rCounting objects:  25% (3/12)\rCounting objects:  33% (4/12)\rCounting objects:  41% (5/12)\rCounting objects:  50% (6/12)\rCounting objects:  58% (7/12)\rCounting objects:  66% (8/12)\rCounting objects:  75% (9/12)\rCounting objects:  83% (10/12)\rCounting objects:  91% (11/12)\rCounting objects: 100% (12/12)\rCounting objects: 100% (12/12), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (8/8), done.\n",
            "Writing objects: 100% (8/8), 5.72 MiB | 5.78 MiB/s, done.\n",
            "Total 8 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/laurenesco/deep-learning.git\n",
            "   fb4fef7..2cf15b7  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# Start HW 3 stuff\n",
        "###\n",
        "%cd /content\n",
        "%ls\n",
        "# Reset the environment\n",
        "%cd /content/\n",
        "%rm -rf deep-learning/\n",
        "%ls\n",
        "# Clone the repo\n",
        "!git clone https://github.com/laurenesco/deep-learning\n",
        "# Navigate to appropriate directory\n",
        "%cd /content/deep-learning/hw3/\n",
        "# Download the datasets\n",
        "!curl -s -L https://www.cs.utexas.edu/~bzhou/dl_class/classification_data.zip -o ./classification_data.zip && unzip -qo classification_data.zip\n",
        "!curl -s -L https://www.cs.utexas.edu/~bzhou/dl_class/drive_data.zip -o ./drive_data.zip && unzip -qo drive_data.zip\n",
        "%ls\n",
        "# Test classifier shape\n",
        "%cd homework/\n",
        "# !python3 models.py\n",
        "\n",
        "%cd /content/deep-learning/hw3/homework/\n",
        "# detector bs\n",
        "%cd /content/deep-learning/hw3/homework/\n",
        "%ls\n",
        "%rm detector.th\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z579Dpat4mQQ",
        "outputId": "b789ce2d-3c71-47e4-b27f-e186d4cdb875"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[0m\u001b[01;34mdeep-learning\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
            "/content\n",
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "Cloning into 'deep-learning'...\n",
            "remote: Enumerating objects: 309, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 309 (delta 87), reused 114 (delta 46), pack-reused 153 (from 1)\u001b[K\n",
            "Receiving objects: 100% (309/309), 88.46 MiB | 23.78 MiB/s, done.\n",
            "Resolving deltas: 100% (133/133), done.\n",
            "/content/deep-learning/hw3\n",
            "bundle.py             classification_data.zip  drive_data.zip  \u001b[0m\u001b[01;34mhomework\u001b[0m/  requirements.txt\n",
            "\u001b[01;34mclassification_data\u001b[0m/  \u001b[01;34mdrive_data\u001b[0m/              \u001b[01;34mgrader\u001b[0m/         README.md\n",
            "/content/deep-learning/hw3/homework\n",
            "/content/deep-learning/hw3/homework\n",
            "/content/deep-learning/hw3/homework\n",
            "classifier.th  \u001b[0m\u001b[01;34mdatasets\u001b[0m/  detector.th  __init__.py  metrics.py  models.py\n",
            "classifier.th  \u001b[0m\u001b[01;34mdatasets\u001b[0m/  __init__.py  metrics.py  models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deep-learning/hw3/\n",
        "!python3 bundle.py homework le7626"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWh27b2aYVOt",
        "outputId": "3b2e58e6-2086-447f-dfeb-bafd3e5ba26d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning/hw3\n",
            "detector.th\n",
            "metrics.py\n",
            "__init__.py\n",
            "datasets\n",
            "models.py\n",
            "classifier.th\n",
            "datasets/road_dataset.py\n",
            "datasets/road_transforms.py\n",
            "datasets/road_utils.py\n",
            "datasets/classification_dataset.py\n",
            "Submission created: /content/deep-learning/hw3/le7626.zip 7.81 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m grader le7626.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rRCCP7ZYq9H",
        "outputId": "ab367d7f-9d6a-4b7b-f763-4c404f4a8781"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public grader loaded.\n",
            "\u001b[97m[INFO     00:00:068] \u001b[0m\u001b[97mClassifier\u001b[0m\n",
            "\u001b[97m[INFO     00:04:922] \u001b[0m\u001b[97m * Classifier                                          [  37 /  35 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:924] \u001b[0m\u001b[97mDetector\u001b[0m\n",
            "\u001b[97m[INFO     00:09:402] \u001b[0m\u001b[97m * Detector                                            [  34 /  65 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:09:402] \u001b[0m\u001b[97mTotal                                                     71 / 100\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/deep-learning/hw3/homework/\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llyIhzu_ZB4m",
        "outputId": "08c71856-c695-4a9b-8e11-7fd2472f60ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning/hw3/homework\n",
            "classifier.th  \u001b[0m\u001b[01;34mdatasets\u001b[0m/  __init__.py  metrics.py  models.py  \u001b[01;34m__pycache__\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# Classification Model\n",
        "###\n",
        "\n",
        "# Train the model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from models import load_model, save_model\n",
        "from datasets.classification_dataset import load_data\n",
        "from metrics import AccuracyMetric\n",
        "\n",
        "# Settings\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "lr = 1e-3\n",
        "\n",
        "# Paths to your train and val folders (each must contain labels.csv + images)\n",
        "train_path = \"/content/deep-learning/hw3/classification_data/train\"\n",
        "val_path = \"/content/deep-learning/hw3/classification_data/val\"\n",
        "\n",
        "# Load data loaders\n",
        "train_loader = load_data(\n",
        "    dataset_path=train_path,\n",
        "    transform_pipeline=\"aug\",        # Data augmentation for training\n",
        "    return_dataloader=True,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_loader = load_data(\n",
        "    dataset_path=val_path,\n",
        "    transform_pipeline=\"default\",    # No augmentation for validation\n",
        "    return_dataloader=True,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Load model\n",
        "model = load_model(\"classifier\", in_channels=3, num_classes=6).to(device)\n",
        "\n",
        "# DEBUG: Show model parameters to confirm they exist\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.shape}\")\n",
        "\n",
        "# Confirm number of parameters\n",
        "print(\"Total params:\", sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "# Training setup\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    metric = AccuracyMetric()\n",
        "    metric.reset()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            preds = model.predict(imgs)\n",
        "            metric.add(preds, labels)\n",
        "\n",
        "    results = metric.compute()\n",
        "    val_acc = results[\"accuracy\"]\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss:.4f}, Val Accuracy = {val_acc:.4f}\")\n",
        "\n",
        "# Save model\n",
        "save_path = save_model(model)\n",
        "print(f\"Model saved to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Iz8RfKTE5PB4",
        "outputId": "fae86fb2-1a71-4124-e911-9f9df83d9607"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3f04a31310a3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets.road_transforms as rt\n",
        "\n",
        "print(\"Module path:\", rt.__file__)\n",
        "print(\"Contents:\", dir(rt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjqjobeELUC6",
        "outputId": "a27d85fb-babb-427e-d8b9-5eddc940a6db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Module path: /content/deep-learning/hw3/homework/datasets/road_transforms.py\n",
            "Contents: ['Compose', 'DepthLoader', 'EgoTrackProcessor', 'Image', 'ImageLoader', 'Path', 'RandomApplyTo', 'RandomHorizontalFlip', 'T', 'Track', 'TrackProcessor', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'create_pose_matrix', 'cv2', 'homogeneous', 'np', 'pad', 'project', 'random', 'rasterize_lines', 'tv_transforms']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# Road Detection Model\n",
        "###\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from models import load_model, save_model\n",
        "from datasets.road_dataset import load_data\n",
        "from metrics import DetectionMetric\n",
        "\n",
        "# Settings\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 30\n",
        "lr = 3e-4\n",
        "batch_size = 32\n",
        "\n",
        "# Load data\n",
        "train_loader = load_data(\n",
        "    dataset_path=\"/content/deep-learning/hw3/drive_data/train\",\n",
        "    return_dataloader=True,\n",
        "    # transform_pipeline=\"aug\",  # use augmented transforms\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_loader = load_data(\n",
        "    dataset_path=\"/content/deep-learning/hw3/drive_data/val\",\n",
        "    return_dataloader=True,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Load model\n",
        "model = load_model(\"detector\").to(device)\n",
        "\n",
        "# Losses\n",
        "seg_loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([0.3, 1.0, 1.0]).to(device))\n",
        "depth_loss_fn = nn.L1Loss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        imgs = batch[\"image\"].to(device)\n",
        "        gt_seg = batch[\"track\"].to(device)      # (B, H, W)\n",
        "        gt_depth = batch[\"depth\"].to(device)    # (B, H, W)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, pred_depth = model(imgs)\n",
        "\n",
        "        seg_loss = seg_loss_fn(logits, gt_seg)\n",
        "        depth_loss = depth_loss_fn(pred_depth, gt_depth)\n",
        "\n",
        "        # loss = seg_loss + 0.5 * depth_loss\n",
        "        # loss = 2 * seg_loss + depth_loss\n",
        "        loss = seg_loss + depth_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    metric = DetectionMetric(num_classes=3)\n",
        "    metric.reset()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch in val_loader:\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            gt_seg = batch[\"track\"].to(device)\n",
        "            gt_depth = batch[\"depth\"].to(device)\n",
        "\n",
        "            pred_seg, pred_depth = model.predict(imgs)\n",
        "            metric.add(pred_seg, gt_seg, pred_depth, gt_depth)\n",
        "\n",
        "    results = metric.compute()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}, mIoU = {results['iou']:.4f}, \"\n",
        "          f\"Depth MAE = {results['abs_depth_error']:.4f}, TP Depth MAE = {results['tp_depth_error']:.4f}\")\n",
        "\n",
        "    scheduler.step(total_loss)\n",
        "\n",
        "# Save model\n",
        "save_path = save_model(model)\n",
        "print(f\"Detector saved to: {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iQWjVojT7m7",
        "outputId": "37dc7f86-c078-47f4-ea97-ae00089f220d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 8000 samples from 16 episodes\n",
            "Loaded 2000 samples from 4 episodes\n",
            "Epoch 1: Loss = 154.6608, mIoU = 0.3240, Depth MAE = 0.0986, TP Depth MAE = 0.0000\n",
            "Epoch 2: Loss = 104.8859, mIoU = 0.3240, Depth MAE = 0.0946, TP Depth MAE = 0.0000\n",
            "Epoch 3: Loss = 97.6853, mIoU = 0.3240, Depth MAE = 0.0844, TP Depth MAE = 0.0000\n",
            "Epoch 4: Loss = 90.0445, mIoU = 0.3240, Depth MAE = 0.0713, TP Depth MAE = 0.0000\n",
            "Epoch 5: Loss = 83.9328, mIoU = 0.3252, Depth MAE = 0.0626, TP Depth MAE = 0.0164\n",
            "Epoch 6: Loss = 79.2580, mIoU = 0.3271, Depth MAE = 0.0595, TP Depth MAE = 0.0174\n",
            "Epoch 7: Loss = 76.3958, mIoU = 0.3419, Depth MAE = 0.0569, TP Depth MAE = 0.0224\n",
            "Epoch 8: Loss = 73.7864, mIoU = 0.3724, Depth MAE = 0.0560, TP Depth MAE = 0.0272\n",
            "Epoch 9: Loss = 71.9761, mIoU = 0.3921, Depth MAE = 0.0544, TP Depth MAE = 0.0250\n",
            "Epoch 10: Loss = 70.2859, mIoU = 0.4059, Depth MAE = 0.0532, TP Depth MAE = 0.0273\n",
            "Epoch 11: Loss = 67.9190, mIoU = 0.4218, Depth MAE = 0.0528, TP Depth MAE = 0.0302\n",
            "Epoch 12: Loss = 65.7802, mIoU = 0.4389, Depth MAE = 0.0530, TP Depth MAE = 0.0281\n",
            "Epoch 13: Loss = 64.0803, mIoU = 0.4457, Depth MAE = 0.0514, TP Depth MAE = 0.0286\n",
            "Epoch 14: Loss = 62.5441, mIoU = 0.4436, Depth MAE = 0.0509, TP Depth MAE = 0.0269\n",
            "Epoch 15: Loss = 61.2743, mIoU = 0.4638, Depth MAE = 0.0506, TP Depth MAE = 0.0270\n",
            "Epoch 16: Loss = 60.5118, mIoU = 0.4688, Depth MAE = 0.0508, TP Depth MAE = 0.0284\n",
            "Epoch 17: Loss = 59.4411, mIoU = 0.4648, Depth MAE = 0.0494, TP Depth MAE = 0.0277\n",
            "Epoch 18: Loss = 58.6269, mIoU = 0.4793, Depth MAE = 0.0490, TP Depth MAE = 0.0266\n",
            "Epoch 19: Loss = 58.0732, mIoU = 0.4759, Depth MAE = 0.0489, TP Depth MAE = 0.0256\n",
            "Epoch 20: Loss = 57.4523, mIoU = 0.4777, Depth MAE = 0.0485, TP Depth MAE = 0.0269\n",
            "Epoch 21: Loss = 56.8820, mIoU = 0.4816, Depth MAE = 0.0479, TP Depth MAE = 0.0261\n",
            "Epoch 22: Loss = 56.4157, mIoU = 0.4873, Depth MAE = 0.0476, TP Depth MAE = 0.0259\n",
            "Epoch 23: Loss = 55.9190, mIoU = 0.4896, Depth MAE = 0.0472, TP Depth MAE = 0.0269\n",
            "Epoch 24: Loss = 55.4969, mIoU = 0.4902, Depth MAE = 0.0468, TP Depth MAE = 0.0269\n",
            "Epoch 25: Loss = 55.1119, mIoU = 0.4925, Depth MAE = 0.0468, TP Depth MAE = 0.0270\n",
            "Epoch 26: Loss = 54.6691, mIoU = 0.4935, Depth MAE = 0.0461, TP Depth MAE = 0.0263\n",
            "Epoch 27: Loss = 54.2441, mIoU = 0.4963, Depth MAE = 0.0458, TP Depth MAE = 0.0265\n",
            "Epoch 28: Loss = 53.9738, mIoU = 0.4938, Depth MAE = 0.0461, TP Depth MAE = 0.0252\n",
            "Epoch 29: Loss = 53.6605, mIoU = 0.4967, Depth MAE = 0.0455, TP Depth MAE = 0.0256\n",
            "Epoch 30: Loss = 53.3858, mIoU = 0.4993, Depth MAE = 0.0451, TP Depth MAE = 0.0265\n",
            "Detector saved to: /content/deep-learning/hw3/homework/detector.th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Troubleshooting detector\n",
        "\n",
        "%cd homework/\n",
        "from models import load_model\n",
        "\n",
        "# Simulate how the autograder loads the model\n",
        "try:\n",
        "    model = load_model(\"detector\", with_weights=True)\n",
        "    print(\"✅ load_model('detector', with_weights=True) worked!\")\n",
        "except Exception as e:\n",
        "    print(\"❌ load_model failed with:\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWdLfrb-jUCr",
        "outputId": "0e2341da-5859-42ed-d567-bb2352387f97"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning/hw3/homework\n",
            "❌ load_model failed with:\n",
            "detector.th not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run local grader\n",
        "%cd /content/deep-learning/hw3/\n",
        "!python3 -m grader homework -v\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WATKGyxgKdsW",
        "outputId": "79927268-38a6-443b-8c8e-d11ec5fff9fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning/hw3\n",
            "Public grader loaded.\n",
            "\u001b[97m[INFO     00:00:002] \u001b[0m\u001b[97mClassifier\u001b[0m\n",
            "\u001b[97m[INFO     00:00:578] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:382] \u001b[0m\u001b[97m  - Accuracy                                           [ 25 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:04:382] \u001b[0m\u001b[33maccuracy: 0.908, required > 0.8\u001b[0m\n",
            "\u001b[97m[INFO     00:04:382] \u001b[0m\u001b[97m  - Accuracy: Extra Credit                             [ 2 / 2 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:387] \u001b[0m\u001b[97m --------------------------------------------------    [  37 /  35 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:04:389] \u001b[0m\u001b[97mDetector\u001b[0m\n",
            "\u001b[97m[INFO     00:04:462] \u001b[0m\u001b[97m  - Predict                                            [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:08:687] \u001b[0m\u001b[33m  - Segmentation Accuracy                              [ 3 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:08:687] \u001b[0m\u001b[33maccuracy: 0.963, required > 0.97\u001b[0m\n",
            "\u001b[33m[WARNING  00:08:688] \u001b[0m\u001b[33m  - Segmentation IoU                                   [ 0 / 25 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:08:688] \u001b[0m\u001b[33miou: 0.499 required > 0.75\u001b[0m\n",
            "\u001b[33m[WARNING  00:08:688] \u001b[0m\u001b[33m  - Segmentation IoU: Extra Credit                     [ 0 / 2 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:08:688] \u001b[0m\u001b[97m  - Depth Error                                        [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:08:689] \u001b[0m\u001b[33mabs_depth_error: 0.045, required < 0.05\u001b[0m\n",
            "\u001b[33m[WARNING  00:08:689] \u001b[0m\u001b[33m  - Depth Error: Extra Credit                          [ 1 / 2 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:08:689] \u001b[0m\u001b[97m  - True Positives Depth Error                         [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:08:689] \u001b[0m\u001b[33mtp_depth_error: 0.026, required < 0.05\u001b[0m\n",
            "\u001b[97m[INFO     00:08:690] \u001b[0m\u001b[97m --------------------------------------------------    [  34 /  65 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:08:690] \u001b[0m\u001b[97mTotal                                                     71 / 100\u001b[0m\n",
            "bundle.py             classification_data.zip  drive_data.zip  \u001b[0m\u001b[01;34mhomework\u001b[0m/   README.md\n",
            "\u001b[01;34mclassification_data\u001b[0m/  \u001b[01;34mdrive_data\u001b[0m/              \u001b[01;34mgrader\u001b[0m/         le7626.zip  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure git\n",
        "!git config --global user.email \"laurenesco@users.noreply.github.com\"\n",
        "!git config --global user.name \"lauren escobedo\"\n",
        "!git remote set-url origin https://laurenesco:<PAT_HERE>@github.com/laurenesco/deep-learning.git\n",
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4xPelc25g9T",
        "outputId": "db2cfbd4-47fb-45db-b59c-8d4859c90a24"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   homework/detector.th\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mclassification_data.zip\u001b[m\n",
            "\t\u001b[31mclassification_data/\u001b[m\n",
            "\t\u001b[31mdrive_data.zip\u001b[m\n",
            "\t\u001b[31mdrive_data/\u001b[m\n",
            "\t\u001b[31mgrader/__pycache__/\u001b[m\n",
            "\t\u001b[31mgrader/datasets/__pycache__/\u001b[m\n",
            "\t\u001b[31mhomework/__pycache__/\u001b[m\n",
            "\t\u001b[31mhomework/datasets/__pycache__/\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqe-BP3barqF",
        "outputId": "a3f95dad-88fb-447f-a45a-772d7ef4ba36"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   homework/detector.th\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mclassification_data.zip\u001b[m\n",
            "\t\u001b[31mclassification_data/\u001b[m\n",
            "\t\u001b[31mdrive_data.zip\u001b[m\n",
            "\t\u001b[31mdrive_data/\u001b[m\n",
            "\t\u001b[31mgrader/__pycache__/\u001b[m\n",
            "\t\u001b[31mgrader/datasets/__pycache__/\u001b[m\n",
            "\t\u001b[31mhomework/__pycache__/\u001b[m\n",
            "\t\u001b[31mhomework/datasets/__pycache__/\u001b[m\n",
            "\t\u001b[31mle7626.zip\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add le7626.zip\n",
        "!git commit -m \"done\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj2WVFsK5iuA",
        "outputId": "67729474-b24b-4857-e979-b95dea2a2b29"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 46ffcf8] done\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 hw3/le7626.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suVuhG8K5kSs",
        "outputId": "2e833aee-1e14-45f2-bc1e-5df2af90b3ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 6, done.\n",
            "Counting objects:  16% (1/6)\rCounting objects:  33% (2/6)\rCounting objects:  50% (3/6)\rCounting objects:  66% (4/6)\rCounting objects:  83% (5/6)\rCounting objects: 100% (6/6)\rCounting objects: 100% (6/6), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 7.81 MiB | 7.29 MiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/laurenesco/deep-learning.git\n",
            "   3262078..46ffcf8  main -> main\n"
          ]
        }
      ]
    }
  ]
}
