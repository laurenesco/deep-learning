{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fca4188-a958-4437-bb9b-a9f96a125f3d",
   "metadata": {},
   "source": [
    "# Deep Networks and Limitations of Linear Models\n",
    "\n",
    "## Why We Need Deep Networks\n",
    "- Linear models have limitations in what they can represent.\n",
    "- Deep networks allow us to solve problems that linear models cannot.\n",
    "\n",
    "## Review of Linear Binary Classification\n",
    "- Task: Separate one class from another (e.g., green vs. red points).\n",
    "- A linear classifier maps from n-dimensional real inputs to a binary output (0 or 1).\n",
    "- This is typically done by applying a **sigmoid** function to a linear model output:\n",
    "\n",
    "$$ y = sigmoid(w^{\\top}x + b) $$\n",
    "\n",
    "<img src=\"./images/bin-class-recap.png\" width=\"500\" style=\"display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "- The sigmoid maps any real number to a value between 0 and 1 (interpreted as probability).\n",
    "\n",
    "## Limitations of Linear Classifiers\n",
    "- Linear classifiers struggle to distinguish between certain input patterns.\n",
    "- Example: Two visually different dog paw images can be indistinguishable to a linear model.\n",
    "- Reason: If the background pixels are the same, and only foreground pixels differ, the model can't capture the distinction due to its linear nature.\n",
    "\n",
    "<img src=\"./images/dog-paws.png\" width=\"500\" style=\"display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "- In linear models, any input between two points with the same label must also receive that same label.\n",
    "- This is problematic when input features (like images) vary in non-linear ways.\n",
    "- If two inputs labeled \"1\" (black and white) are on opposite sides, the in-between (gray) must also be labeled \"1\" â€” even if it shouldn't.\n",
    "\n",
    "## XOR: A Classic Limitation\n",
    "- Linear models cannot express the XOR logic function.\n",
    "- They can model AND and OR, but not XOR.\n",
    "- XOR requires non-linear decision boundaries.\n",
    "\n",
    "<img src=\"./images/xor.png\" width=\"500\" style=\"display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## Can Stacking Linear Models Help?\n",
    "- No. Stacking multiple linear layers still results in a linear model.\n",
    "- Mathematically, combining multiple linear transformations still yields a single linear transformation.\n",
    "- Weights and biases just collapse into one equivalent layer.\n",
    "\n",
    "<img src=\"./images/add-lin.png\" width=\"500\" style=\"display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "## The Solution: Add Non-Linearity\n",
    "- To overcome these limitations, we insert **non-linear functions** between layers.\n",
    "- These break the linearity and allow the network to model complex relationships.\n",
    "\n",
    "<img src=\"./images/non-lin.png\" width=\"500\" style=\"display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "### Common Non-Linear Function: ReLU\n",
    "- ReLU: `ReLU(x) = max(0, x)`\n",
    "- ReLU introduces non-linearity and is simple to compute.\n",
    "\n",
    "## Moving Forward\n",
    "- We'll explore how to build **deep networks** by:\n",
    "- Stacking linear layers with non-linear activations.\n",
    "- Adjusting the training setup and loss functions accordingly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
