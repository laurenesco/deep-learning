{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4886c92a-992a-4ffc-a146-9034757dd606",
   "metadata": {},
   "source": [
    "# Lecture Notes: Introduction to Training Very Deep Networks\n",
    "\n",
    "## Recap\n",
    "\n",
    "In the previous section, we learned how to train basic deep networks.\n",
    "\n",
    "Now, let's ask:  \n",
    "What happens if we try to train a very deep network — say, with 100 layers?\n",
    "\n",
    "## What Happens If We Go Deep?\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/401.png\" width=\"500\" style=\"display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "- The answer is surprisingly simple:\n",
    "  - It won’t train.\n",
    "  - The network fails to learn effectively as the depth increases.\n",
    "\n",
    "## Goal of This Section\n",
    "\n",
    "We’ll explore:\n",
    "- Why deep networks fail to train\n",
    "- What we can do to fix it\n",
    "- How to design networks that scale to hundreds or even thousands of layers\n",
    "\n",
    "## Breakdown of the Section\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./images/402.png\" width=\"500\" style=\"display: block; margin: auto;\">\n",
    "\n",
    "<br>\n",
    "\n",
    "1. Case Study: Deep Linear Networks  \n",
    "   - We'll begin with very deep linear networks  \n",
    "   - These are easier to understand and give us useful insights  \n",
    "   - Most conclusions will also apply to non-linear networks  \n",
    "\n",
    "2. Normalization Techniques  \n",
    "   - We'll examine how normalization methods (e.g., batch norm) help stabilize training  \n",
    "   - Acts as a structural regularizer to support deeper architectures  \n",
    "\n",
    "3. Residual Connections  \n",
    "   - A key strategy for preserving gradient flow during backpropagation  \n",
    "   - Enables successful training of very deep models  \n",
    "   - Forms the foundation of architectures like ResNet\n",
    "\n",
    "## End Goal\n",
    "\n",
    "By the end of this section, you should be able to:\n",
    "\n",
    "- Understand why deeper networks are harder to train\n",
    "- Use normalization and residual connections to address those challenges\n",
    "- Train deep architectures with hundreds or thousands of layers, if needed\n",
    "\n",
    "We’ll begin by studying the behavior of deep linear networks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
